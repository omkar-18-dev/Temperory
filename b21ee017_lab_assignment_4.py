# -*- coding: utf-8 -*-
"""B21EE017_Lab_Assignment_4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SC9sG9zngcy8DyMYug7AAr35SB9U_Lgo
"""

# Imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as drawplot
from scipy import linalg
import math
import random
from sklearn.model_selection import train_test_split as div

# Q1  

data = pd.read_csv("iris.txt",header = None)

#print(type(df))
#print(data)
data.columns = ['X0','X1','X2','X3','Y']
#print(data)
X_data = data.drop(['Y'],axis = 1)
Y_data = data.drop(['X0','X1','X2','X3'],axis = 1)

#print(X_data)
#print(Y_data)
dicto = {}
for i in Y_data['Y']:
  if(i not in dicto):
    dicto[i] = 1
key = list(dicto.keys())
#print(len(key))
for i in range(len(key)):
  Y_data['Y'] = Y_data['Y'].replace(key[i],i+1)
X_train,X_test,Y_train,Y_test = div(X_data,Y_data,train_size = 0.7,shuffle = True)

X_train = X_train.to_numpy()
X_test = X_test.to_numpy()
Y_train = Y_train.to_numpy()
Y_test = Y_test.to_numpy()
print(Y_train.shape)

#Q1 part 1) and part2)

class gaussianbayesclassifier :

  def __init__(self,classifiertype,covar):
    self.classifiertype = classifiertype
    #self.covarmatrix = covar
    if(self.classifiertype == 'a'):
      self.covarmatrix = covar
      self.sd = covar
    elif(self.classifiertype == 'b'):
      self.covarmatrix = covar
    else:
      pass
  
  def Train(self,X_data,Y_data):

    classcount = 0;
    classes = {}
    for i in Y_data:
      if i[0] not in classes:
        classes[i[0]] = 1
        classcount += 1
      else:
        classes[i[0]] += 1
   
   
    temp = X_data.shape
    size,feature_count = temp[0],temp[1]   
    self.features = feature_count
    lis = list(classes.keys())
    lis.sort()
    self.clas = lis
    self.Pwi = np.zeros((1,classcount))
    self.mean_vec = np.zeros((classcount,feature_count))
   
    classwiselist = []
    vec = []
    varlist = np.zeros((self.features,self.features))
    
    for i in range(self.features):
      for j in range(self.features):
        templis = []
        templis1 = []
        templis2 = []
        for k in range(size):
          templis.append(X_data[k][i] * X_data[k][j])
          templis1.append(X_data[k][i])
          templis2.append(X_data[k][j])
        tempi = np.array(templis)
        templis1 = np.array(templis1)
        templis2 = np.array(templis2)
      varlist[i][j] = abs(np.mean(tempi) - np.mean(templis1) * np.mean(templis2))
    self.overallvar = varlist
   
   
    for i in range(self.features):
      sum = 0
      for j in range(size):
        sum += X_data[j][i]
      vec.append(sum/size)
    self.overallmean = vec
    for i in range(classcount):
      target = self.clas[i]
      A = []
      for k in range(size):
        if(Y_data[k][0] == target):
          T = []
          for j in range(self.features):
            T.append(X_data[k][j])
          A.append(T)
      B = np.asarray(A)
      #print(B)
      classwiselist.append(B)
    minmaxvals = []
    for i in range(self.features):
      maxi = X_data[0][i]
      mini = X_data[0][i]
      for j in range(1,size):
        t = X_data[j][i]
        if(t>maxi):
          maxi = t
        if(t<mini):
          mini = t
      minmaxvals.append((mini,maxi))
    self.minimax = minmaxvals
    #print(len(classwiselist))
    for i in range(classcount):
      for j in range(feature_count):
        sum = 0
        for k in range(size):
          if(Y_data[k][0] == self.clas[i]):
            sum += X_data[k][j]
        self.mean_vec[i][j] = sum/classes[self.clas[i]]
      self.Pwi[0][i] = classes[self.clas[i]]/size
    if(self.classifiertype == 'b'):
      #self.covarmatrix = np.array(self.covarmatrix)
      self.sigma_matrix = np.linalg.inv(self.covarmatrix)
    elif(self.classifiertype == 'c'):
      self.sigma_matrix = []
      
      mean = []
      for p in range(len(self.clas)):
        temp2 = np.zeros((feature_count,feature_count))
        siz1 = classes[self.clas[p]]
        for i in range(feature_count):
          dt = classwiselist[p]
          sum = 0
          for j in range(siz1):
            sum += dt[j][i]
          mean.append(sum/siz1)
        for i in range(feature_count):
          for j in range(feature_count):
            sum = 0
            for k in range(siz1):
              sum += (X_data[k][i] - mean[i])*(X_data[k][j] - mean[j])
            temp2[i][j] = sum/siz1
        self.sigma_matrix.append(np.linalg.inv(temp2))
        #print(self.sigma_matrix)    
  
  
  def Test(self,X_Test,Y_Test):
    temp = X_Test.shape
    size = temp[0]
    prediction = np.zeros((1,size))

    if(self.classifiertype == 'a'):
      for i in range(size):
        temp = []
        x_vec = np.zeros((self.features,1))
        ui = np.zeros((self.features,1))
        for j in range(self.features):
          x_vec[j][0] = X_Test[i][j]
        for j in range(len(self.clas)):
          for k in range(self.features):
             ui[k][0] = self.mean_vec[j][k]
          wi = ui /(self.sd)**2
          wiz = -0.5 * np.matmul(ui.T,ui)[0]/self.sd **2 + math.log(self.Pwi[0][j])
          val = np.matmul(wi.T,x_vec)[0] + wiz
          temp.append(val)
        max = -1000000000
        index = -1
        for k in range(len(self.clas)):
          if(temp[k]>max):
            max = temp[k]
            index = k
        prediction[0][i] = self.clas[index]
    
    
    elif(self.classifiertype == 'b'):
      #self.sigma_matrix = np.array(sigma_matrix)
      for i in range(size):
        temp = []
        x_vec = np.zeros((self.features,1))
        ui = np.zeros((self.features,1))
        for j in range(self.features):
          x_vec[j][0] = X_Test[i][j]
        for j in range(len(self.clas)):
          for k in range(self.features):
             ui[k][0] = self.mean_vec[j][k]
          wi = np.matmul(self.sigma_matrix,ui)
          mat = np.matmul(ui.T,self.sigma_matrix)
          wiz = -0.5 * np.matmul(mat,ui)[0] + math.log(self.Pwi[0][j])
          val = np.matmul(wi.T,x_vec)[0] + wiz
          temp.append(val)
        max = -10000000000
        index = -1
        for k in range(len(self.clas)):
          if(temp[k]>max):
            max = temp[k]
            index = k
        prediction[0][i] = self.clas[index]  
    
    else:
      for i in range(size):
        temp = []
        x_vec = np.zeros((self.features,1))
        ui = np.zeros((self.features,1))
        for j in range(self.features):
          x_vec[j][0] = X_Test[i][j]
        for j in range(len(self.clas)):
          for k in range(self.features):
             ui[k][0] = self.mean_vec[j][k]
          covmat = self.sigma_matrix[j]
          wi = np.matmul(covmat,ui)
          mat = np.matmul(ui.T,covmat)
          wiz = -0.5 * np.matmul(mat,ui)[0] + 0.5 * math.log(abs(np.linalg.det(covmat))) + math.log(self.Pwi[0][j])
          Wi = -0.5 * covmat
          m1 = np.matmul(x_vec.T,Wi)
          val = np.matmul(m1,x_vec)[0] +np.matmul(wi.T,x_vec)[0] + wiz
          temp.append(val)
        max = -10000000000
        index = -1
        for k in range(len(self.clas)):
          if(temp[k]>max):
            max = temp[k]
            index = k
        prediction[0][i] = self.clas[index] 
    c = 0 
    for i in range(size):
      if(Y_Test[i] == prediction[0][i]):
        c += 1
    accu = c/size
    self.accuracy = accu
    self.testpredict = prediction
  

  def Predict(self,X_vals):
    if(self.classifiertype == 'a'):
      temp = []
      x_vec = np.zeros((self.features,1))
      ui = np.zeros((self.features,1))
      for j in range(self.features):
        x_vec[j][0] = X_vals[j]
      for j in range(len(self.clas)):
        for k in range(self.features):
            ui[k][0] = self.mean_vec[j][k]
        wi = ui /(self.sd)**2
        wiz = -0.5 * np.matmul(ui.T,ui)[0]/self.sd **2 + math.log(self.Pwi[0][j])
        val = np.matmul(wi.T,x_vec)[0] + wiz
        temp.append(val)
      max = -1000000000
      index = -1
      for k in range(len(self.clas)):
        if(temp[k]>max):
          max = temp[k]
          index = k
      return(self.clas[index])
    
    
    elif(self.classifiertype == 'b'):
      #self.sigma_matrix = np.array(sigma_matrix)
      temp = []
      x_vec = np.zeros((self.features,1))
      ui = np.zeros((self.features,1))
      for j in range(self.features):
        x_vec[j][0] = X_vals[j]
      for j in range(len(self.clas)):
        for k in range(self.features):
            ui[k][0] = self.mean_vec[j][k]
        wi = np.matmul(self.sigma_matrix,ui)
        mat = np.matmul(ui.T,self.sigma_matrix)
        wiz = -0.5 * np.matmul(mat,ui)[0] + math.log(self.Pwi[0][j])
        val = np.matmul(wi.T,x_vec)[0] + wiz
        temp.append(val)
      max = -10000000000
      index = -1
      for k in range(len(self.clas)):
        if(temp[k]>max):
          max = temp[k]
          index = k
      return(self.clas[index])  
    
    else:
      temp = []
      x_vec = np.zeros((self.features,1))
      ui = np.zeros((self.features,1))
      for j in range(self.features):
        x_vec[j][0] = X_vals[i][j]
      for j in range(len(self.clas)):
        for k in range(self.features):
            ui[k][0] = self.mean_vec[j][k]
        covmat = self.sigma_matrix[j]
        wi = np.matmul(covmat,ui)
        mat = np.matmul(ui.T,covmat)
        wiz = -0.5 * np.matmul(mat,ui)[0] + 0.5 * math.log(abs(np.linalg.det(covmat))) + math.log(self.Pwi[0][j])
        Wi = -0.5 * covmat
        m1 = np.matmul(x_vec.T,Wi)
        val = np.matmul(m1,x_vec)[0] +np.matmul(wi.T,x_vec)[0] + wiz
        temp.append(val)
      max = -10000000000
      index = -1

      for k in range(len(self.clas)):
        if(temp[k]>max):
          max = temp[k]
          index = k
      return(self.clas[index]) 
   

  def PlotDecBound(self,f1,f2):
    lx,hx = self.minimax[f1][0] - abs(self.overallvar[f1][f2]),self.minimax[f1][1] + abs(self.overallvar[f1][f2])
    ly,hy = self.minimax[f2][0] - abs(self.overallvar[f1][f2]),self.minimax[f2][1] + abs(self.overallvar[f1][f2])
    Xx = np.linspace(lx,hx,1000)
    Yy = np.linspace(ly,hy,1000)
    print(lx,hx,ly,hy)
    colrs = []
    for i in range(self.features):
      random_color=list(np.random.choice(range(255),size=3))
      colrs.append(random_color)
    Col = []
    Xcord = np.zeros((1,1000000))
    Ycord = np.zeros((1,1000000))
    count = 0
    for i in range(1000):
      for j in range(1000):
        li = []
        for k in range(self.features):
          li.append(self.overallmean[k])
        li[f1] = Xx[i]
        li[f2] = Yy[j]
        pred = self.Predict(li)
        Col.append(colrs[self.clas.index(pred)])
        Xcord[0][count] = Xx[i]
        Ycord[0][count] = Yy[j]
        count += 1
    cols = np.array(Col)
    fig,ax = drawplot.subplots(figsize=(3,3))
    #ax = fig.add_subplot(111, projection = '2d')
    ax.scatter(Xcord, Ycord, c = cols/255.0)
    #print(Xx,Yy)
    drawplot.show()

#Q1 part 3)

model1 = gaussianbayesclassifier('a',1)
model2 = gaussianbayesclassifier('b',[[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]])
model3 = gaussianbayesclassifier('c',9)
model1.Train(X_train,Y_train)
model1.Test(X_test,Y_test)
model2.Train(X_train,Y_train)
model2.Test(X_test,Y_test)
model3.Train(X_train,Y_train)
model3.Test(X_test,Y_test)
print(model1.Predict([4.4,2.9,1.9,0.9]))
print(model1.Predict([4.4,2.9,1.9,0.9]))
print(model1.Predict([4.4,2.9,1.9,0.9]))
print(model1.accuracy,model2.accuracy,model3.accuracy)
#print(model1.testpredict)
#print(model2.testpredict)
#print(model3.testpredict)
#print(list(Y_test))
model1.PlotDecBound(1,2)

#Q1 part 5)

angle = np.linspace(0,2*np.pi,10000)
r = np.random.uniform(0.0,5.0,(10000))
Y = []
angle_test = np.linspace(0,2*np.pi,100)
r_test = np.random.uniform(0.0,5.0,(100))
Y_test = []
for i in range(10000):
  if(r[i]<=3.0):
    Y.append(1)
  else:
    Y.append(2)
for i in range(100):
  if(r_test[i]<=3.0):
    Y_test.append(1)
  else:
    Y_test.append(2)
data = np.zeros((10000,2))
test_data = np.zeros((100,2))
for i in range(10000):
  data[i][0] = r[i] * math.cos(angle[i])
  data[i][1] = r[i] * math.sin(angle[i])
for i in range(100):
  test_data[i][0] = r[i] * math.cos(angle_test[i] * 90 / np.pi)
  test_data[i][1] = r[i] * math.sin(angle_test[i] * 90 / np.pi)
Y_ = np.zeros((10000,1))
Y_test_ = np.zeros((100,1))
for j in range(10000):
  Y_[j][0] = Y[j]
for j in range(100):
  Y_test_[j][0] = Y_test[j]


model =gaussianbayesclassifier('a',3)
model.Train(data,Y_)
model.Test(test_data,Y_test_)
#model.accuracy
#model.PlotDecBound(0,1)
#print(Y_test_)

# Q2 part 1
#Initializing given data
mean = np.array([0,0])
cov_matrix = np.array([[3/2,1/2],
                       [1/2,3/2]])
data = np.random.multivariate_normal(mean, cov_matrix,750)

def getcovarmatrix(data): #Function written from scratch to get a 2 x 2 covariance matrix 
  size = data.shape[0]
  zz = 0
  zo = 0
  
  oz = 0
  oo = 0
  xmean = 0
  ymean = 0
  for i in range(size):
      xmean += data[i][0]
      ymean += data[i][1]
  xmean /= size
  ymean /= size
  for j in range(size):
    zz += (data[j][0] - xmean)**2
    zo += (data[j][0] - xmean)*(data[j][1] - ymean)
    oz += (data[j][0] - xmean)*(data[j][1] - ymean)
    oo += (data[j][1] - ymean)**2
  zz /= size
  zo /= size
  oz /= size
  oo /= size
  newcov_matrix = np.array([[zz,zo],[oz,oo]])
  return newcov_matrix

covar_matrix_gen = getcovarmatrix(data) # Covariance matrix

eigenvals, eigenvectors = np.linalg.eig(covar_matrix_gen) # getting eigenvalues and eigenvectors

# Plotting data (Blue points) and eigenvectors(Red Points)
X = []
Y = []
for i in range(data.shape[0]):
  X.append(data[i][0])
for i in range(data.shape[0]):
  Y.append(data[i][1])
X1 = [eigenvectors[0]]
Y1 = [eigenvectors[1]]
drawplot.scatter(X, Y, c ="blue")
drawplot.scatter(X1,Y1, c = 'red')
drawplot.show()

# Q2 part 2
#Transforming the dataset
trans1 = linalg.inv(covar_matrix_gen)
trans2 = linalg.sqrtm(trans1)

data_new = data @ trans2 # New covarinace matrix
covar_matrix_trans = getcovarmatrix(data_new)
print(covar_matrix_trans)
# Resasoning :
# In the new covariance matrix cov(X,X) and cov(Y,Y) are 1 and 
# cov(X,Y) is almost zero. This implies that the both X and Y are 
# independant in the distribution. Hence this transformation has made
# X and Y independant and normalized the dataset

#Q2 part 3
theta = np.linspace(0, 2*np.pi, 10)
Px = np.sin(theta)
Py = np.cos(theta)
colrs = []
for i in range(10):
  Px[i] *= 5
  Py[i] *= 5
  random_color=list(np.random.choice(range(255),size=3))
  colrs.append(random_color)
cols = np.array(colrs)
fig, ax = drawplot.subplots(figsize=(5,5))
ax.scatter(Px,Py, c=cols/255.0, s = 50)
fig.show()

def dist (x,y):
  return((x**2 + y**2)**0.5)

distances = []
for i in range(10):
  distances.append(dist(Px[i],Py[i]))

points = []

for i in range(10):
  points.append(i + 1)



fig = drawplot.figure(figsize = (10, 5))
 
drawplot.bar(points, distances, color = 'red',
        width = 0.4)

#Q2 Part 3)
trans1 = linalg.inv(cov_matrix)
trans2 = linalg.sqrtm(trans1)

data = np.zeros((10,2))
for i in range(10):
  data[i][0] = Px[i]
  data[i][1] = Py[i]

#data = np.hstack((Px.T,Py.T))

Q = data @ trans2 # New covarinace matrix
#print(Q)

P_x = Q[:,0]
P_y = Q[:,1]

distances_2 = []
for i in range(10):
  distances_2.append(dist(P_x[i],P_y[i]))

points_2 = []

for i in range(10):
  points_2.append(i)

print(len(points_2),len(distances_2))
fig = drawplot.figure(figsize = (10, 5))
 
drawplot.bar(points_2, distances_2, color = 'red',
       width = 0.4)

fig, ax = drawplot.subplots(figsize=(5,5))
ax.scatter(Px,Py, c=cols/255.0, s = 50)
ax.scatter(P_x,P_y, c=cols/255.0, s = 50)
fig.show()